{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import supportingFunctions as sf\n",
    "import model_torch as mm\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Set these parameters carefully\n",
    "nLayers = 5\n",
    "epochs = 50\n",
    "batchSize = 1\n",
    "gradientMethod = 'AG'\n",
    "K = 1\n",
    "sigma = 0.01\n",
    "restoreWeights = False\n",
    "\n",
    "# To train the model with higher K values (K > 1), such as K = 5 or 10, it is better\n",
    "# to initialize with a pre-trained model with K = 1.\n",
    "if K > 1:\n",
    "    restoreWeights = True\n",
    "    restoreFromModel = '04Jun_0243pm_5L_1K_100E_AG'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#%% Generate a meaningful filename to save the trainined models for testing\n",
    "print('*************************************************')\n",
    "start_time = time.time()\n",
    "saveDir = 'savedModels/'\n",
    "directory = saveDir + datetime.now().strftime(\"%d%b_%I%M%P_\") + \\\n",
    "             str(nLayers) + 'L_' + str(K) + 'K_' + str(epochs) + 'E_' + gradientMethod\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "sessFileName= directory+'/model'\n",
    "\n",
    "#%% Save test model\n",
    "csmT = torch.randn((1, 12, 256, 232), dtype=torch.complex64, device=device, requires_grad=False)\n",
    "maskT = torch.randn((1, 256, 232), dtype=torch.complex64, device=device, requires_grad=False)\n",
    "atbT = torch.randn((1, 256, 232, 2), dtype=torch.float32, device=device, requires_grad=False)\n",
    "\n",
    "out = mm.makeModel(atbT, csmT, maskT, False, nLayers, K, gradientMethod)\n",
    "predTst = out['dc'+str(K)]\n",
    "predTst = predTst.clone().detach().requires_grad_(False)\n",
    "sessFileNameTst = directory+'/modelTst'\n",
    "\n",
    "saver = torch.save(predTst, sessFileNameTst)\n",
    "print('Testing model saved')\n",
    "\n",
    "#%% Read multi-channel dataset\n",
    "trnOrg, trnAtb, trnCsm, trnMask = sf.getData('training')\n",
    "trnOrg, trnAtb = sf.c2r(trnOrg), sf.c2r(trnAtb)\n",
    "\n",
    "#%%\n",
    "csmP = torch.zeros((batchSize, 12, 256, 232), dtype=torch.complex64, device=device, requires_grad=False)\n",
    "maskP = torch.zeros((batchSize, 256, 232), dtype=torch.complex64, device=device, requires_grad=False)\n",
    "atbP = torch.zeros((batchSize, 256, 232, 2), dtype=torch.float32, device=device, requires_grad=False)\n",
    "orgP = torch.zeros((batchSize, 256, 232, 2), dtype=torch.float32, device=device, requires_grad=False)\n",
    "\n",
    "#%% Creating the dataset\n",
    "nTrn = trnOrg.shape[0]\n",
    "nBatch = int(np.floor(np.float32(nTrn) / batchSize))\n",
    "nSteps = nBatch * epochs\n",
    "\n",
    "trnData = torch.utils.data.TensorDataset(orgP, atbP, csmP, maskP)\n",
    "trnData = torch.utils.data.DataLoader(trnData, batch_size=batchSize, shuffle=True)\n",
    "iterator = iter(trnData)\n",
    "\n",
    "#%% Make training model\n",
    "out = mm.makeModel(atbT, csmT, maskT, True, nLayers, K, gradientMethod)\n",
    "predT = out['dc' + str(K)]\n",
    "predT = predT.clone().detach().requires_grad_(True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([predT])\n",
    "\n",
    "print('training started at', datetime.now().strftime(\"%d-%b-%Y %I:%M %P\"))\n",
    "print('parameters are: Epochs:', epochs, ' BS:', batchSize, 'nSteps:', nSteps, 'nSamples:', nTrn)\n",
    "\n",
    "model_params = list(out.values())\n",
    "saver = torch.save(model_params, sessFileName) # PyTorch saves the weights, not the meta graph\n",
    "totalLoss, ep = [], 0\n",
    "writer = SummaryWriter(directory)\n",
    "for step in tqdm(range(nSteps)):\n",
    "    try:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(predT, target) # target should be defined\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalLoss.append(loss.item())\n",
    "        if np.remainder(step + 1, nBatch) == 0:\n",
    "            ep = ep + 1\n",
    "            avgTrnLoss = np.mean(totalLoss)\n",
    "            writer.add_scalar(\"TrnLoss\", avgTrnLoss, ep)\n",
    "            totalLoss = []  # after each epoch empty the list of total loss\n",
    "    except:\n",
    "        break\n",
    "torch.save(model_params, sessFileName) # PyTorch saves the weights, not the meta graph\n",
    "writer.close()\n",
    "\n",
    "end_time = time.time()\n",
    "print('Training completed in minutes ', ((end_time - start_time) / 60))\n",
    "print('training completed at', datetime.now().strftime(\"%d-%b-%Y %I:%M %P\"))\n",
    "print('*************************************************')\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
