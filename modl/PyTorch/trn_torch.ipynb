{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import supportingFunctions as sf\n",
    "import model_torch as mm\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "'#Pytorch adaptation of trnV2Compat.py'\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Set these parameters carefully\n",
    "nLayers = 5\n",
    "epochs = 50\n",
    "batchSize = 1\n",
    "gradientMethod = 'AG'\n",
    "K = 1\n",
    "sigma = 0.01\n",
    "restoreWeights = False\n",
    "\n",
    "# To train the model with higher K values (K > 1), such as K = 5 or 10, it is better\n",
    "# to initialize with a pre-trained model with K = 1.\n",
    "if K > 1:\n",
    "    restoreWeights = True\n",
    "    restoreFromModel = '04Jun_0243pm_5L_1K_100E_AG'\n",
    "\n",
    "if restoreWeights:\n",
    "    wts = sf.getWeights('savedModels/' + restoreFromModel)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Generate a meaningful filename to save the trainined models for testing\n",
    "print('*************************************************')\n",
    "start_time = time.time()\n",
    "saveDir = 'savedModels/'\n",
    "cwd = os.getcwd()\n",
    "directory = saveDir + datetime.now().strftime(\"%d%b_%I%M%P_\") + \\\n",
    "    str(nLayers) + 'L_' + str(K) + 'K_' + str(epochs) + 'E_' + gradientMethod\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "sessFileName = directory + '/model'\n",
    "\n",
    "'#Pytorch translation of the below code'\n",
    "\n",
    "#%% save test model\n",
    "\n",
    "csmT = torch.complex(torch.zeros((None, 12, 256, 232)), torch.zeros((None, 12, 256, 232)))\n",
    "maskT = torch.complex(torch.zeros((None, 256, 232)), torch.zeros((None, 256, 232)))\n",
    "atbT = torch.zeros((None, 256, 232, 2))\n",
    "\n",
    "out = mm.makeModel(atbT, csmT, maskT, False, nLayers, K, gradientMethod)\n",
    "predTst = out['dc' + str(K)]\n",
    "predTst = torch.identity(predTst, name='predTst')\n",
    "sessFileNameTst = directory + '/modelTst'\n",
    "\n",
    "saver = torch.train.Saver()\n",
    "with torch.Session() as sess:\n",
    "    sess.run(torch.global_variables_initializer())\n",
    "    savedFile = saver.save(sess, sessFileNameTst, latest_filename='checkpointTst')\n",
    "print('testing model saved:' + savedFile)\n",
    "\n",
    "#%% read multi-channel dataset\n",
    "trnOrg, trnAtb, trnCsm, trnMask = sf.getData('training')\n",
    "trnOrg, trnAtb = sf.c2r(trnOrg), sf.c2r(trnAtb)\n",
    "\n",
    "#%%\n",
    "\n",
    "csmP = torch.complex(torch.zeros((None, None, None, None)), torch.zeros((None, None, None, None)))\n",
    "maskP = torch.complex(torch.zeros((None, None, None)), torch.zeros((None, None, None)))\n",
    "atbP = torch.zeros((None, None, None, 2))\n",
    "orgP = torch.zeros((None, None, None, 2))\n",
    "\n",
    "#%% creating the dataset\n",
    "nTrn = trnOrg.shape[0]\n",
    "nBatch = int(np.floor(np.float32(nTrn) / batchSize))\n",
    "nSteps = nBatch * epochs\n",
    "\n",
    "trnData = torch.data.Dataset.from_tensor_slices((orgP, atbP, csmP, maskP))\n",
    "trnData = trnData.cache()\n",
    "trnData = trnData.repeat(count=epochs)\n",
    "trnData = trnData.shuffle(buffer_size=1000)\n",
    "trnData = trnData.batch(batchSize)\n",
    "trnData = trnData.prefetch(buffer_size=1)\n",
    "iterator = torch.data.Iterator.from_structure(trnData.output_types, trnData.output_shapes)\n",
    "orgT, atbT, csmT, maskT = iterator.get_next()\n",
    "#----------------------------------------------------------- aqui me quede####\n",
    "\"#Pytorch translation of the below code\"\n",
    "\n",
    "#%% make training model\n",
    "\n",
    "out=mm.makeModel(atbT,csmT,maskT,True,nLayers,K,gradientMethod)\n",
    "predT=out['dc'+str(K)]\n",
    "predT=torch.identity(predT,name='pred')\n",
    "loss = torch.reduce_mean(torch.reduce_sum(torch.pow(predT-orgT, 2),axis=0))\n",
    "torch.summary.scalar('loss', loss)\n",
    "update_ops = torch.get_collection(torch.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with torch.name_scope('optimizer'):\n",
    "    optimizer = torch.train.AdamOptimizer()\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(torch.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "    opToRun=optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "#%% training code\n",
    "\n",
    "print ('training started at', datetime.now().strftime(\"%d%b_%I%M%P\"))\n",
    "print ('parameters are: Epochs:',epochs,' BS:',batchSize,'nSteps:',nSteps,'nSamples:',nTrn)\n",
    "\n",
    "saver = torch.train.Saver(max_to_keep=100)\n",
    "totalLoss,ep=[],0\n",
    "lossT = torch.placeholder(tf.float32)\n",
    "lossSumT = torch.summary.scalar(\"TrnLoss\", lossT)\n",
    "\n",
    "with torch.Session() as sess:\n",
    "    sess.run(torch.global_variables_initializer())\n",
    "    if restoreWeights:\n",
    "        sess=sf.assignWts(sess,nLayers,wts)\n",
    "\n",
    "    feedDict={orgP:trnOrg,atbP:trnAtb, maskP:trnMask,csmP:trnCsm}\n",
    "    sess.run(iterator.make_initializer(trnData), feed_dict=feedDict)\n",
    "    savedFile = saver.save(sess, sessFileName)\n",
    "    print('Model meta graph saved:' + savedFile)\n",
    "\n",
    "    writer = torch.summary.FileWriter(directory, sess.graph)\n",
    "    for step in tqdm(range(nSteps)):\n",
    "        try:\n",
    "            tmp,_,_=sess.run([loss,opToRun,update_ops])\n",
    "            totalLoss.append(tmp)\n",
    "            if np.remainder(step+1,nBatch)==0:\n",
    "                ep=ep+1\n",
    "                avgTrnLoss=np.mean(totalLoss)\n",
    "                lossSum=sess.run(lossSumT,feed_dict={lossT:avgTrnLoss})\n",
    "                writer.add_summary(lossSum, ep)\n",
    "                totalLoss=[]\n",
    "        except torch.errors.OutOfRangeError:\n",
    "            break\n",
    "    savedfile=saver.save(sess, sessFileName, global_step=ep)\n",
    "    writer.close()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print ('total time taken:', ((end_time - start_time) /60))\n",
    "    print ('training completed at', datetime.now().strftime(\"%d%b_%I%M%P\"))\n",
    "    print ('*************************************************')\n",
    "\n",
    "    #%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
